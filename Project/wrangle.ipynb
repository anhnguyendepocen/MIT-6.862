{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Get dataframe of image filenames\n",
    "files = []\n",
    "file_names = []\n",
    "for file_name in os.listdir('images'):\n",
    "    # Remove 'S_' and file extensions\n",
    "    num = file_name.strip('S_').strip('.gif').strip('.GIF')\n",
    "    \n",
    "    # Find and replace letters\n",
    "    num = num.replace(\"A\", \"01\")\n",
    "    num = num.replace(\"B\", \"02\")\n",
    "    num = num.replace(\"L\", \"01\")\n",
    "    num = num.replace(\"R\", \"02\")\n",
    "    num = num.replace(\"M\", \"02\")\n",
    "    num = num.replace(\"X\", \"01\")\n",
    "    num = num.replace(\"Y\", \"02\")\n",
    "    num = num.replace(\"Z\", \"03\")\n",
    "    num = num.replace(\"I\", \"01\")\n",
    "    num = num.replace(\"O\", \"02\")\n",
    "    num = num.replace(\"U\", \"02\")\n",
    "    num = num.replace(\"S\", \"02\")\n",
    "    \n",
    "    files.append(int(num))\n",
    "    file_names.append(file_name)\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df['id'] = files\n",
    "df['file_name'] = file_names\n",
    "\n",
    "# Get dataframe of Wisconsin csv\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Merge dataframes on ID\n",
    "df_merged = df.merge(data, on='id')\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(data[data['id_join'].str.endswith(('01', '02', '03'))][['id', 'diagnosis']])\n",
    "#     print(df_merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94642857 0.96396396 0.98198198 0.98181818 0.96363636]\n",
      "0.9675658125658126 0.013312796964389143\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16.26</td>\n",
       "      <td>21.88</td>\n",
       "      <td>107.50</td>\n",
       "      <td>826.8</td>\n",
       "      <td>0.11650</td>\n",
       "      <td>0.12830</td>\n",
       "      <td>0.17990</td>\n",
       "      <td>0.07981</td>\n",
       "      <td>0.1869</td>\n",
       "      <td>0.06532</td>\n",
       "      <td>...</td>\n",
       "      <td>17.730</td>\n",
       "      <td>25.21</td>\n",
       "      <td>113.70</td>\n",
       "      <td>975.2</td>\n",
       "      <td>0.14260</td>\n",
       "      <td>0.21160</td>\n",
       "      <td>0.3344</td>\n",
       "      <td>0.1047</td>\n",
       "      <td>0.2736</td>\n",
       "      <td>0.07953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16.26</td>\n",
       "      <td>21.88</td>\n",
       "      <td>107.50</td>\n",
       "      <td>826.8</td>\n",
       "      <td>0.11650</td>\n",
       "      <td>0.12830</td>\n",
       "      <td>0.17990</td>\n",
       "      <td>0.07981</td>\n",
       "      <td>0.1869</td>\n",
       "      <td>0.06532</td>\n",
       "      <td>...</td>\n",
       "      <td>17.730</td>\n",
       "      <td>25.21</td>\n",
       "      <td>113.70</td>\n",
       "      <td>975.2</td>\n",
       "      <td>0.14260</td>\n",
       "      <td>0.21160</td>\n",
       "      <td>0.3344</td>\n",
       "      <td>0.1047</td>\n",
       "      <td>0.2736</td>\n",
       "      <td>0.07953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>549</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>551</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>554 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0          16.26         21.88          107.50      826.8          0.11650   \n",
       "1          16.26         21.88          107.50      826.8          0.11650   \n",
       "2          17.99         10.38          122.80     1001.0          0.11840   \n",
       "3          20.57         17.77          132.90     1326.0          0.08474   \n",
       "4          19.69         21.25          130.00     1203.0          0.10960   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "549        21.56         22.39          142.00     1479.0          0.11100   \n",
       "550        20.13         28.25          131.20     1261.0          0.09780   \n",
       "551        16.60         28.08          108.30      858.1          0.08455   \n",
       "552        20.60         29.33          140.10     1265.0          0.11780   \n",
       "553         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0             0.12830         0.17990              0.07981         0.1869   \n",
       "1             0.12830         0.17990              0.07981         0.1869   \n",
       "2             0.27760         0.30010              0.14710         0.2419   \n",
       "3             0.07864         0.08690              0.07017         0.1812   \n",
       "4             0.15990         0.19740              0.12790         0.2069   \n",
       "..                ...             ...                  ...            ...   \n",
       "549           0.11590         0.24390              0.13890         0.1726   \n",
       "550           0.10340         0.14400              0.09791         0.1752   \n",
       "551           0.10230         0.09251              0.05302         0.1590   \n",
       "552           0.27700         0.35140              0.15200         0.2397   \n",
       "553           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "0                   0.06532  ...        17.730          25.21   \n",
       "1                   0.06532  ...        17.730          25.21   \n",
       "2                   0.07871  ...        25.380          17.33   \n",
       "3                   0.05667  ...        24.990          23.41   \n",
       "4                   0.05999  ...        23.570          25.53   \n",
       "..                      ...  ...           ...            ...   \n",
       "549                 0.05623  ...        25.450          26.40   \n",
       "550                 0.05533  ...        23.690          38.25   \n",
       "551                 0.05648  ...        18.980          34.12   \n",
       "552                 0.07016  ...        25.740          39.42   \n",
       "553                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0             113.70       975.2           0.14260            0.21160   \n",
       "1             113.70       975.2           0.14260            0.21160   \n",
       "2             184.60      2019.0           0.16220            0.66560   \n",
       "3             158.80      1956.0           0.12380            0.18660   \n",
       "4             152.50      1709.0           0.14440            0.42450   \n",
       "..               ...         ...               ...                ...   \n",
       "549           166.10      2027.0           0.14100            0.21130   \n",
       "550           155.00      1731.0           0.11660            0.19220   \n",
       "551           126.70      1124.0           0.11390            0.30940   \n",
       "552           184.60      1821.0           0.16500            0.86810   \n",
       "553            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.3344                0.1047          0.2736   \n",
       "1             0.3344                0.1047          0.2736   \n",
       "2             0.7119                0.2654          0.4601   \n",
       "3             0.2416                0.1860          0.2750   \n",
       "4             0.4504                0.2430          0.3613   \n",
       "..               ...                   ...             ...   \n",
       "549           0.4107                0.2216          0.2060   \n",
       "550           0.3215                0.1628          0.2572   \n",
       "551           0.3403                0.1418          0.2218   \n",
       "552           0.9387                0.2650          0.4087   \n",
       "553           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "0                    0.07953  \n",
       "1                    0.07953  \n",
       "2                    0.11890  \n",
       "3                    0.08902  \n",
       "4                    0.08758  \n",
       "..                       ...  \n",
       "549                  0.07115  \n",
       "550                  0.06637  \n",
       "551                  0.07820  \n",
       "552                  0.12400  \n",
       "553                  0.07039  \n",
       "\n",
       "[554 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traditional machine learning benchmark\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Store labels\n",
    "y = df_merged[\"diagnosis\"]\n",
    "\n",
    "# Drop useless columns\n",
    "df = df_merged.drop(columns=['id', 'diagnosis', 'file_name', 'Unnamed: 32'])\n",
    "\n",
    "# model = LogisticRegression()\n",
    "# model = GaussianNB()\n",
    "model = XGBClassifier()\n",
    "\n",
    "scores = cross_val_score(model, df, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores), np.std(scores))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def file_to_array(file_name):\n",
    "    \"\"\"For each string `file_name`, open that image and return a numpy array.\"\"\"\n",
    "    img = Image.open('images/'+ file_name)\n",
    "    img = img.convert(\"RGB\")\n",
    "    return np.array(img)\n",
    "\n",
    "df_merged['image'] = df_merged['file_name'].apply(file_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\i_can\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[[[240 248 248]\\n  [240 248 248]\\n  [240 248 248]\\n  ...\\n  [232 248 248]\\n  [232 248 248]\\n  [232 248 248]]\\n\\n [[240 248 248]\\n  [240 248 248]\\n  [240 248 248]\\n  ...\\n  [232 248 248]\\n  [232 248 248]\\n  [232 248 248]]\\n\\n [[208 248 248]\\n  [232 248 248]\\n  [208 248 248]\\n  ...\\n  [208 248 248]\\n  [208 248 248]\\n  [208 248 248]]\\n\\n ...\\n\\n [[240 248 248]\\n  [240 248 248]\\n  [232 248 248]\\n  ...\\n  [232 248 248]\\n  [232 248 248]\\n  [232 248 248]]\\n\\n [[240 248 248]\\n  [232 248 248]\\n  [208 248 248]\\n  ...\\n  [232 248 248]\\n  [208 248 248]\\n  [208 248 248]]\\n\\n [[232 248 248]\\n  [232 248 248]\\n  [232 248 248]\\n  ...\\n  [208 248 248]\\n  [208 248 248]\\n  [208 248 248]]]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9dbc2c61265c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_test_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mtrain_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mtrain_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_X\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '[[[240 248 248]\\n  [240 248 248]\\n  [240 248 248]\\n  ...\\n  [232 248 248]\\n  [232 248 248]\\n  [232 248 248]]\\n\\n [[240 248 248]\\n  [240 248 248]\\n  [240 248 248]\\n  ...\\n  [232 248 248]\\n  [232 248 248]\\n  [232 248 248]]\\n\\n [[208 248 248]\\n  [232 248 248]\\n  [208 248 248]\\n  ...\\n  [208 248 248]\\n  [208 248 248]\\n  [208 248 248]]\\n\\n ...\\n\\n [[240 248 248]\\n  [240 248 248]\\n  [232 248 248]\\n  ...\\n  [232 248 248]\\n  [232 248 248]\\n  [232 248 248]]\\n\\n [[240 248 248]\\n  [232 248 248]\\n  [208 248 248]\\n  ...\\n  [232 248 248]\\n  [208 248 248]\\n  [208 248 248]]\\n\\n [[232 248 248]\\n  [232 248 248]\\n  [232 248 248]\\n  ...\\n  [208 248 248]\\n  [208 248 248]\\n  [208 248 248]]]'"
     ]
    }
   ],
   "source": [
    "# CNN time - split the data.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "df_cnn = df_merged[['diagnosis', 'image']]\n",
    "# Cast labels as integers, 1 for Malignant, 0 for benign\n",
    "df_cnn['diagnosis'] = (df_cnn['diagnosis'] == 'M').astype(int) \n",
    "\n",
    "def create_model():\n",
    "    # Specify model\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(32, (5, 5), input_shape=(480, 640, 3), padding='same', activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Conv2D(32, (5, 5), activation='relu', padding='same'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Conv2D(32, (5, 5), activation='relu', padding='same'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(120, activation='relu'))\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=(480, 640, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(480, 640, 3)))\n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "#     return model\n",
    "    \n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(100, input_dim=921600, activation='relu'))\n",
    "#     model.add(Dense(100, activation='relu'))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "\n",
    "for _ in range(1):\n",
    "    # Split data\n",
    "    df_train, df_test = train_test_split(df_cnn, test_size=0.2)\n",
    "    df_train_X, df_train_y = df_train['image'], df_train['diagnosis']\n",
    "    df_test_X, df_test_y = df_test['image'], df_test['diagnosis']\n",
    "\n",
    "    train_X = np.stack(df_train_X.values)\n",
    "    train_y = df_train_y.values\n",
    "    test_X = np.stack(df_test_X.values)\n",
    "    test_y = df_test_y.values\n",
    "    \n",
    "    train_X = train_X.astype(\"float32\")\n",
    "    test_X = test_X.astype(\"float32\")\n",
    "    train_X = train_X / 255\n",
    "    test_X = test_X / 255\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = create_model()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "#     # Reshape if necessary\n",
    "#     train_X = train_X.reshape(train_X.shape[0], train_X.shape[1]*train_X.shape[2]*train_X.shape[3])\n",
    "#     test_X = test_X.reshape(test_X.shape[0], test_X.shape[1]*test_X.shape[2]*test_X.shape[3])\n",
    "\n",
    "    # Train model and output cross-validated accuracy\n",
    "    model.fit(train_X, train_y, validation_data=(test_X, test_y), epochs=12, batch_size=12, verbose=1)\n",
    "    scores = model.evaluate(test_X, test_y, verbose=0)\n",
    "    print(scores)\n",
    "    print(test_y)\n",
    "    print(model.predict_classes(test_X, verbose=1))\n",
    "\n",
    "    #     print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(test_y == 0)/len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
